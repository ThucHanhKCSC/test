{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad17601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026e4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e612002",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"TaiLieu/train-0.csv\", header=None, skiprows=1).sample(frac=1)\n",
    "val_df   = pd.read_csv(r\"TaiLieu/file-0.csv\", header=None, skiprows=1).sample(frac=1)\n",
    "test_df  = pd.read_csv(r\"TaiLieu/file-1.csv\", header=None, skiprows=1).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6645b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL TRAIN:  156\n",
      "LABEL VAL:  222\n",
      "LABEL TEST:  179\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array(train_df.iloc[:, 2]) #lấy cột 2 là cột nhãn \n",
    "train_x = np.array(train_df.iloc[:,3:]) #lấy cột 3 làm đặc trưng\n",
    "unique, counts = np.unique(train_y, return_counts=True)\n",
    "print(\"LABEL TRAIN: \", len(unique))\n",
    "\n",
    "val_y = np.array(val_df.iloc[:, 2]) #lấy cột 2 là cột nhãn \n",
    "val_x = np.array(val_df.iloc[:,3:]) #lấy cột 3 làm đặc trưng\n",
    "unique_v, counts_ = np.unique(val_y, return_counts=True)\n",
    "print(\"LABEL VAL: \", len(unique_v))\n",
    "\n",
    "test_y = np.array(test_df.iloc[:, 2]) #lấy cột 2 là cột nhãn \n",
    "test_x = np.array(test_df.iloc[:,3:]) #lấy cột 3 làm đặc trưng\n",
    "unique_t, counts_t = np.unique(test_y, return_counts=True)\n",
    "print(\"LABEL TEST: \", len(unique_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2221b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25713, 1908) (25713,)\n",
      "(3260, 1908) (3260,)\n",
      "(3217, 1908) (3217,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "SIZE = 1908\n",
    "SIZE2= 1\n",
    "N_CLASSES = 228\n",
    "LR = 0.001\n",
    "N_EPOCHS = 15\n",
    "\n",
    "print(train_x.shape,train_y.shape)\n",
    "print(val_x.shape,val_y.shape)\n",
    "print(test_x.shape,test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1868e97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   4   5   6  12  13  15  18  22  24  25  26  31  32  33  34  35\n",
      "  36  39  40  41  42  43  44  46  47  48  49  51  52  54  56  58  60  62\n",
      "  63  64  66  67  68  69  71  72  73  74  75  76  77  78  79  83  84  85\n",
      "  87  88  89  92  95  98 100 102 104 106 108 109 110 111 112 116 117 120\n",
      " 121 123 124 125 126 130 132 133 134 139 142 145 148 149 150 151 152 153\n",
      " 155 156 157 158 160 161 163 164 166 167 169 171 172 173 175 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], SIZE2, SIZE, 1)\n",
    "val_x = val_x.reshape(val_x.shape[0], SIZE2, SIZE, 1)\n",
    "test_x = test_x.reshape(test_x.shape[0], SIZE2, SIZE, 1)\n",
    "\n",
    "LABELS = np.unique(train_y)\n",
    "original_test_y = test_y\n",
    "\n",
    "train_y = to_categorical(train_y, N_CLASSES)\n",
    "val_y = to_categorical(val_y, N_CLASSES)\n",
    "test_y = to_categorical(test_y, N_CLASSES)\n",
    "\n",
    "print(LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f2a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input0 = Input(shape=(SIZE2,SIZE,1))\n",
    "conv1 = Conv2D(32, kernel_size=2, activation='relu', padding=\"same\" ,input_shape=(SIZE2, SIZE, 1))(input0)\n",
    "pool1 = MaxPooling2D((2, 2), padding = 'same')(conv1)\n",
    "conv2 = Conv2D(32, kernel_size=2, activation='relu', padding=\"same\")(pool1)\n",
    "pool2 = MaxPooling2D((2, 2), padding = 'same')(conv2)\n",
    "\n",
    "conv3 = Conv2D(64, kernel_size=2, activation='relu', padding=\"same\")(pool2)\n",
    "pool3 = MaxPooling2D((2, 2), padding = 'same')(conv3)\n",
    "'''\n",
    "conv4 = Conv2D(64, kernel_size=2, activation='relu', padding=\"same\")(pool3)\n",
    "pool4 = MaxPooling2D((2, 2), padding = 'same')(conv4)\n",
    "'''\n",
    "flatten_per = Flatten()(pool3)\n",
    "\n",
    "hidden1 = Dense(1024, activation='relu')(flatten_per)\n",
    "output = Dense(N_CLASSES, activation='softmax')(hidden1)\n",
    "\n",
    "model = Model(inputs=input0, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0674d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y if (y.ndim == 1 or y.shape[1] == 1) else np.argmax(y, axis=1)\n",
    "        self.reports = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_hat = np.asarray(self.model.predict(self.x))\n",
    "        y_hat = np.where(y_hat > 0.5, 1, 0) if (y_hat.ndim == 1 or y_hat.shape[1] == 1)  else np.argmax(y_hat, axis=1)\n",
    "        report = classification_report(self.y,y_hat,output_dict=True)\n",
    "        self.reports.append(report)\n",
    "        return\n",
    "   \n",
    "    # Utility method\n",
    "    def get(self, metrics, of_class):\n",
    "        return [report[str(of_class)][metrics] for report in self.reports]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b246968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "804/804 [==============================] - 187s 232ms/step - loss: 0.5169 - accuracy: 0.8765 - val_loss: 0.4856 - val_accuracy: 0.9166\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Echidna\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Echidna\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Echidna\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/804 [==============>...............] - ETA: 1:16 - loss: 0.1296 - accuracy: 0.9529"
     ]
    }
   ],
   "source": [
    "metrics_multiclass = Metrics(train_x, train_y)\n",
    "history = model.fit(train_x, train_y, epochs=N_EPOCHS, batch_size = BATCH_SIZE ,validation_data=(val_x, val_y), callbacks=[metrics_multiclass])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea39b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
